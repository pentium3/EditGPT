{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset web_nlg (/Users/mirackchan/.cache/huggingface/datasets/web_nlg/release_v1/0.0.0/28ffb892f7f42450dd9558684aa43bcaf44b1b3bf0d77cb8d73534646af88dda)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97a59b1c7e443b8e8829bf56a30be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"web_nlg\", \"release_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset few_rel (/Users/mirackchan/.cache/huggingface/datasets/few_rel/default/1.0.0/7ffe000cdd243be21a5984bfb4cad86c2b7c421c93a405c1dbc4f55b69565158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad4fb8e3484baabd8dd8444b9f87f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"few_rel\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 'train_wiki' split of the dataset\n",
    "train_data = dataset['train_wiki']\n",
    "train_data[1000]\n",
    "# \" \".join(train_data[1000]['tokens'])\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations = set()\n",
    "for example in train_data:\n",
    "    relations.add(example[\"names\"][0])\n",
    "num_relations = len(relations)\n",
    "num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relation': 'P140',\n",
       " 'tokens': ['Ideologically',\n",
       "  ',',\n",
       "  '19th',\n",
       "  'century',\n",
       "  'Catholic',\n",
       "  'missionaries',\n",
       "  'in',\n",
       "  'Vietnam',\n",
       "  'taught',\n",
       "  'their',\n",
       "  'Vietnamese',\n",
       "  'converts',\n",
       "  'the',\n",
       "  'doctrines',\n",
       "  'expounded',\n",
       "  'by',\n",
       "  '17th',\n",
       "  'century',\n",
       "  'missionary',\n",
       "  'Alexandre',\n",
       "  'de',\n",
       "  'Rhodes',\n",
       "  'in',\n",
       "  'his',\n",
       "  'seminal',\n",
       "  'bilingual',\n",
       "  'Latin',\n",
       "  '-',\n",
       "  'Vietnamese',\n",
       "  'Catechism',\n",
       "  '.'],\n",
       " 'head': {'text': 'alexandre de rhodes',\n",
       "  'type': 'Q336653',\n",
       "  'indices': [[19, 20, 21]]},\n",
       " 'tail': {'text': 'catholic', 'type': 'Q1841', 'indices': [[4]]},\n",
       " 'names': ['religion',\n",
       "  'religion of a person, organization or religious building, or associated with this subject']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The name was at one point changed to Nottingham East Midlands Airport so as to include the name of the city that is supposedly most internationally recognisable , mainly due to the Robin Hood legend .'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(train_data[1]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tjq'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['head']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tanjung pandan'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['tail']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'place served by transport hub'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['names'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Merpati flight 106 departed Jakarta ( CGK ) on a domestic flight to Tanjung Pandan ( TJQ ) .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_data[0]\n",
    "\" \".join(x['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'known_id': 0,\n",
       " 'subject': 'tjq',\n",
       " 'attribute': 'tanjung pandan',\n",
       " 'template': ' \"{}, a territorial entity or entities served by this transport hub (airport, train station, etc.)\",',\n",
       " 'prediction': ' \"Tanjung Pandan to serve as a transport hub for the area. \"',\n",
       " 'prompt': ' \"Tjq, a territorial entity or entities served by this transport hub (airport, train station, etc.)\",',\n",
       " 'relation_id': 'P931'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open the file and load its contents as JSON\n",
    "with open('data.json','r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_new_rl(relations,instance):\n",
    "    random_relation = None\n",
    "    while not random_relation or random_relation == instance[\"names\"][0]:\n",
    "        random_relation = random.choice(list(relations))\n",
    "    return random_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"counterfact_re.json\"\n",
    "new_result =[]\n",
    "def generate_new_data(idx,instance):\n",
    "    src = \" \".join(instance['tokens']).lower()\n",
    "    prompt = \"what is the {} between \"+instance['head']['text'] + \" and \" + instance['tail']['text'] + \" in the following sentence \\'\" + src +\"\\' ?\"\n",
    "    prompt=prompt.lower()\n",
    "    old = instance['names'][0].lower()\n",
    "    new = get_new_rl(relations,instance).lower()\n",
    "    return{\n",
    "        \"case_id\":idx,\n",
    "        \"requested_rewrite\": {\n",
    "            \"prompt\": prompt,\n",
    "            \"relation_id\": \"P103\",\n",
    "            \"target_new\": {\n",
    "                \"str\": new,\n",
    "                \"id\": \"Q1860\"\n",
    "            },\n",
    "            \"target_true\": {\n",
    "                \"str\": old,\n",
    "                \"id\": \"Q150\"\n",
    "            },\n",
    "            \"subject\": \"relation\"\n",
    "        },\n",
    "        \"paraphrase_prompts\": [\"describe the relationship of \"+instance['head']['text'] + \" and \" + instance['tail']['text'] + \" in the following sentence \\'\" + src +\"\\' :\"],\n",
    "        \"neighborhood_prompts\": [],\n",
    "        \"attribute_prompts\": [],\n",
    "        \"generation_prompts\": [\"what is the relation between \"+instance['head']['text'] + \" and \" + instance['tail']['text']+\" ?\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place served by transport hub\n",
      "located in the administrative territorial entity\n",
      "{'case_id': 0, 'requested_rewrite': {'prompt': \"what is the {} between tjq and tanjung pandan in the following sentence 'merpati flight 106 departed jakarta ( cgk ) on a domestic flight to tanjung pandan ( tjq ) .'\", 'relation_id': 'P103', 'target_new': {'str': 'place served by transport hub', 'id': 'Q1860'}, 'target_true': {'str': 'located in the administrative territorial entity', 'id': 'Q150'}, 'subject': 'relation'}, 'paraphrase_prompts': [], 'neighborhood_prompts': [], 'attribute_prompts': [], 'generation_prompts': []}\n"
     ]
    }
   ],
   "source": [
    "print(generate_new_data(0,train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for i in range(44800):\n",
    "    instance = train_data[i]\n",
    "    new_result.append(generate_new_data(i,instance))\n",
    "\n",
    "with open(output,'w') as f:\n",
    "    json.dump(new_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case_id': 2000,\n",
       " 'requested_rewrite': {'prompt': \"what is the {} between alexandre de rhodes and catholic in the following sentence 'ideologically , 19th century catholic missionaries in vietnam taught their vietnamese converts the doctrines expounded by 17th century missionary alexandre de rhodes in his seminal bilingual latin - vietnamese catechism .' ?\",\n",
       "  'relation_id': 'P103',\n",
       "  'target_new': {'str': 'notable work', 'id': 'Q1860'},\n",
       "  'target_true': {'str': 'religion', 'id': 'Q150'},\n",
       "  'subject': 'relation'},\n",
       " 'paraphrase_prompts': [\"describe the relationship of alexandre de rhodes and catholic in the following sentence 'ideologically , 19th century catholic missionaries in vietnam taught their vietnamese converts the doctrines expounded by 17th century missionary alexandre de rhodes in his seminal bilingual latin - vietnamese catechism .' :\"],\n",
       " 'neighborhood_prompts': [],\n",
       " 'attribute_prompts': [],\n",
       " 'generation_prompts': ['what is the relation between alexandre de rhodes and catholic ?']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('counterfact_re.json','r') as f:\n",
    "    data_new = json.load(f)\n",
    "data_new[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select every 10th sample\n",
    "new_data = []\n",
    "for i in range(0, len(data_new), 10):\n",
    "    new_data.append(data_new[i])\n",
    "\n",
    "# Save the new JSON file\n",
    "with open('counterfact_re_sampled.json', 'w') as f:\n",
    "    json.dump(new_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"new_data.json\"\n",
    "new_result =[]\n",
    "def generate_new_data(instance,old_data):\n",
    "    relation_triple_id = old_data['known_id']\n",
    "    subject = old_data['subject'].lower()\n",
    "    relation = instance['names'][1].lower()\n",
    "    template = old_data['template'].lower()\n",
    "    prediction = instance['names'][1].lower()\n",
    "    prompt = \" \".join(instance['tokens']).lower()\n",
    "    relation_id = old_data['relation_id']\n",
    "\n",
    "    return {\n",
    "        \"relation_triple_id\":relation_triple_id,\n",
    "        \"subject\":subject,\n",
    "        \"relation\":relation,\n",
    "        \"template\":template,\n",
    "        \"prediction\":prediction,\n",
    "        \"prompt\":prompt,\n",
    "        \"relaiton_id\":relation_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4000):\n",
    "    instance = train_data[i]\n",
    "    old_data = data[i]\n",
    "    new_result.append(generate_new_data(instance,old_data))\n",
    "\n",
    "with open(output,'w') as f:\n",
    "    json.dump(new_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relation_triple_id': 0,\n",
       " 'subject': 'tjq',\n",
       " 'relation': 'territorial entity or entities served by this transport hub (airport, train station, etc.)',\n",
       " 'template': ' \"{}, a territorial entity or entities served by this transport hub (airport, train station, etc.)\",',\n",
       " 'prediction': 'territorial entity or entities served by this transport hub (airport, train station, etc.)',\n",
       " 'prompt': 'merpati flight 106 departed jakarta ( cgk ) on a domestic flight to tanjung pandan ( tjq ) .',\n",
       " 'relaiton_id': 'P931'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('new_data.json','r') as f:\n",
    "    data_new = json.load(f)\n",
    "data_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4000):\n",
    "    cur = data[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def generate_fields(subject, attribute, relation):\n",
    "    prompt = \"\\\"subject\\\": \\\"MacApp\\\", \\n\\\"attribute\\\":\\\"Apple\\\",\\n\\\"template\\\": \\\"{}, a product created by\\\",\\n\\\"prediction\\\":\\\"Apple to help developers create apps for the iPhone and\\\",\\n\\\"prompt\\\": \\\"MacApp, a product created by\\\",\\n\"\n",
    "    prompt += f\"\\nSimilar to above, create template, prediction , prompt for the following:\\n\\nSubject: {subject}\\nAttribute: {attribute}\\nRelation: {relation}\\n\\n Template, prompt, prediction:\"\n",
    "\n",
    "    # print(prompt)\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "# res = generate_fields(train_data[2000]['head']['text'], train_data[2000]['tail']['text'],train_data[2000]['names'][1])\n",
    "# print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_instance(instance,index):\n",
    "    subject = instance[\"head\"]['text']\n",
    "    attribute = instance[\"tail\"][\"text\"]\n",
    "    relation = instance[\"names\"][1]\n",
    "    generated_text = generate_fields(subject, attribute, relation)\n",
    "    tmp = generated_text.split(\"\\n\")\n",
    "    template = tmp[0].split(\":\")[1] if 0<len(tmp) and \":\" in tmp[0] else \"\"\n",
    "    prompt = tmp[1].split(\":\")[1] if 1<len(tmp) and \":\" in tmp[1] else \"\"\n",
    "    prediction = tmp[2].split(\":\")[1] if 2<len(tmp) and \":\" in tmp[2] else \"\"\n",
    "    #return generated_text\n",
    "\n",
    "    return {\n",
    "        \"known_id\": index,\n",
    "        \"subject\": subject,\n",
    "        \"attribute\": attribute,\n",
    "        \"template\": template,\n",
    "        \"prediction\": prediction,\n",
    "        \"prompt\": prompt,\n",
    "        \"relation_id\": instance['relation']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "result = []\n",
    "for i in range(1000):\n",
    "    time.sleep(1)\n",
    "    res = convert_instance(train_data[i],i)\n",
    "    result.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "result2 = []\n",
    "for i in range(1000,2000):\n",
    "    #time.sleep(1)\n",
    "    res = convert_instance(train_data[i],i)\n",
    "    result2.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data.json\"\n",
    "with open(output_file, 'a') as f:\n",
    "    json.dump(result2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "result3 = []\n",
    "for i in range(2000,3000):\n",
    "    #time.sleep(1)\n",
    "    res = convert_instance(train_data[i],i)\n",
    "    result3.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data.json\"\n",
    "with open(output_file, 'a') as f:\n",
    "    json.dump(result3, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
